# =============================================================================
# DocBases v2.0 - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# IMPORTANT: Never commit your .env file with real API keys!
# =============================================================================

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Choose your LLM provider. Supported options:
#   - openai   : OpenAI GPT models (requires OPENAI_API_KEY)
#   - google   : Google Gemini models (requires GOOGLE_API_KEY)
#   - groq     : Groq models (requires GROQ_API_KEY)
#   - ollama   : Local Ollama models (requires LLM_API_BASE)
# -----------------------------------------------------------------------------
LLM_PROVIDER=openai

# LLM Model to use. Examples for each provider:
#   OpenAI  : gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
#   Google  : gemini-1.5-pro, gemini-1.5-flash, gemini-2.0-flash-exp
#   Groq    : llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768
#   Ollama  : llama3.2, mistral, codellama, phi3
# -----------------------------------------------------------------------------
LLM_MODEL=gpt-4o-mini

# API Base URL (required for Ollama, optional for others)
# For Ollama, use: http://localhost:11434
# For OpenAI-compatible APIs, specify the base URL here
# -----------------------------------------------------------------------------
# LLM_API_BASE=http://localhost:11434

# =============================================================================
# EMBEDDING PROVIDER CONFIGURATION
# =============================================================================
# Choose your embedding provider. Supported options:
#   - openai   : OpenAI embeddings (requires OPENAI_API_KEY)
#   - google   : Google embeddings (requires GOOGLE_API_KEY)
#   - ollama   : Local Ollama embeddings (requires EMB_API_BASE)
# -----------------------------------------------------------------------------
EMB_PROVIDER=openai

# Embedding Model to use. Examples for each provider:
#   OpenAI  : text-embedding-3-small, text-embedding-3-large, text-embedding-ada-002
#   Google  : models/text-embedding-004, models/embedding-001
#   Ollama  : nomic-embed-text, mxbai-embed-large, all-minilm
# -----------------------------------------------------------------------------
EMB_MODEL=text-embedding-3-small

# Embedding API Base URL (required for Ollama)
# For Ollama, use: http://localhost:11434
# -----------------------------------------------------------------------------
# EMB_API_BASE=http://localhost:11434

# =============================================================================
# API KEYS
# =============================================================================
# Only fill in the API key(s) for the provider(s) you're using.
# Get your API keys from:
#   OpenAI  : https://platform.openai.com/api-keys
#   Google  : https://aistudio.google.com/app/apikey
#   Groq    : https://console.groq.com/keys
# -----------------------------------------------------------------------------
OPENAI_API_KEY=
GOOGLE_API_KEY=
GROQ_API_KEY=

# =============================================================================
# RAG MODE CONFIGURATION
# =============================================================================
# Choose the RAG (Retrieval-Augmented Generation) mode:
#   - basic       : Simple retrieve-and-generate pipeline (fastest)
#   - corrective  : Self-correcting RAG with relevance checking
#   - adaptive    : Adaptive RAG that routes queries intelligently
#   - multi_agent : Multi-agent RAG with specialized agents
# -----------------------------------------------------------------------------
RAG_MODE=basic

# =============================================================================
# DOCUMENT PROCESSING
# =============================================================================
# Document chunking strategy:
#   - recursive : Split by character with recursive chunking (default, fastest)
#   - semantic  : Split by semantic meaning (slower, better quality)
# -----------------------------------------------------------------------------
CHUNKING_STRATEGY=recursive

# Use Docling for advanced document parsing (PDF, DOCX, etc.)
# Set to "true" for better document structure extraction
# Requires additional dependencies: pip install docling
# -----------------------------------------------------------------------------
USE_DOCLING=false

# =============================================================================
# PERSISTENCE & CHECKPOINTING
# =============================================================================
# Enable persistent memory for conversation continuity
# When true, conversations are saved and can be resumed
# -----------------------------------------------------------------------------
USE_PERSISTENT_MEMORY=true

# Path to the SQLite database for checkpoints
# Default: knowledges/checkpoints.db
# -----------------------------------------------------------------------------
# CHECKPOINT_DB_PATH=knowledges/checkpoints.db

# Path to the SQLite database for metrics
# Default: knowledges/metrics.db
# -----------------------------------------------------------------------------
# METRICS_DB_PATH=knowledges/metrics.db

# =============================================================================
# OBSERVABILITY - LANGSMITH (Optional)
# =============================================================================
# Enable LangSmith tracing for debugging and monitoring
# Get your API key from: https://smith.langchain.com/
# -----------------------------------------------------------------------------
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=doc-bases

# =============================================================================
# QUICK START EXAMPLES
# =============================================================================
#
# --- Example 1: OpenAI (Cloud) ---
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4o-mini
# EMB_PROVIDER=openai
# EMB_MODEL=text-embedding-3-small
# OPENAI_API_KEY=sk-your-key-here
#
# --- Example 2: Google Gemini (Cloud) ---
# LLM_PROVIDER=google
# LLM_MODEL=gemini-1.5-flash
# EMB_PROVIDER=google
# EMB_MODEL=models/text-embedding-004
# GOOGLE_API_KEY=your-key-here
#
# --- Example 3: Ollama (Local/Free) ---
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.2
# LLM_API_BASE=http://localhost:11434
# EMB_PROVIDER=ollama
# EMB_MODEL=nomic-embed-text
# EMB_API_BASE=http://localhost:11434
#
# --- Example 4: Groq (Fast Cloud) ---
# LLM_PROVIDER=groq
# LLM_MODEL=llama-3.3-70b-versatile
# EMB_PROVIDER=openai
# EMB_MODEL=text-embedding-3-small
# GROQ_API_KEY=gsk_your-key-here
# OPENAI_API_KEY=sk-your-key-here  # Groq doesn't have embeddings
#
# =============================================================================
